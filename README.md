Projeto de IdentificaÃ§Ã£o BiomÃ©trica Facial com CNN
ğŸ“‹ Sobre o Projeto

Este projeto implementa um sistema de identificaÃ§Ã£o biomÃ©trica facial utilizando Redes Neurais Convolucionais (CNNs) para aprendizado de representaÃ§Ãµes discriminativas diretamente dos dados brutos. O sistema Ã© treinado e avaliado utilizando um subconjunto da base de dados CelebA.

Objetivo Geral: Desenvolver um sistema robusto de identificaÃ§Ã£o facial baseado em CNNs capaz de reconhecer identidades em condiÃ§Ãµes variadas de iluminaÃ§Ã£o, expressÃ£o e pose.
ğŸ¯ Objetivos EspecÃ­ficos

    Implementar uma CNN para reconhecimento facial

    Avaliar o impacto de diferentes tÃ©cnicas de prÃ©-processamento

    Comparar resultados com abordagens tradicionais

    Analisar desempenho, acurÃ¡cia e limitaÃ§Ãµes do sistema

    Implementar aumento de dados com cGAN (opcional)

ğŸ“Š Dataset
CelebA Subset

    Origem: CelebA (Celebrities Attributes Dataset)

    Tamanho original: 202.599 imagens (10.177 identidades)

    Subconjunto utilizado: 20% da base original (â‰ˆ40.520 imagens)

    ResoluÃ§Ã£o: 64Ã—64 pixels (otimizado de trabalho anterior)

    Formato: Grayscale (1 canal)

    DistribuiÃ§Ã£o: â‰ˆ2.000 identidades, mÃ©dia de 20 imagens por identidade

DivisÃ£o dos Dados

    Treino: 70% (â‰ˆ28.364 imagens)

    ValidaÃ§Ã£o: 15% (â‰ˆ6.078 imagens)

    Teste: 15% (â‰ˆ6.078 imagens)

ğŸ—ï¸ Arquitetura do Sistema
1. PrÃ©-processamento

    Redimensionamento para 64Ã—64 pixels

    NormalizaÃ§Ã£o de pixels para [0, 1]

    Data augmentation (flip horizontal, rotaÃ§Ãµes leves, ajuste de brilho)

    One-hot encoding dos rÃ³tulos

2. Arquitetura CNN Principal
text

Camada de Entrada: (64, 64, 1)
â”œâ”€â”€ Conv2D(32, 3Ã—3) + ReLU + BatchNorm
â”œâ”€â”€ MaxPooling2D(2Ã—2) + Dropout(0.25)
â”œâ”€â”€ Conv2D(64, 3Ã—3) + ReLU + BatchNorm
â”œâ”€â”€ MaxPooling2D(2Ã—2) + Dropout(0.25)
â”œâ”€â”€ Conv2D(128, 3Ã—3) + ReLU + BatchNorm
â”œâ”€â”€ MaxPooling2D(2Ã—2) + Dropout(0.25)
â”œâ”€â”€ Conv2D(256, 3Ã—3) + ReLU + BatchNorm
â”œâ”€â”€ MaxPooling2D(2Ã—2) + Dropout(0.25)
â”œâ”€â”€ Flatten()
â”œâ”€â”€ Dense(512) + ReLU + BatchNorm + Dropout(0.5)
â””â”€â”€ Dense(N_classes) + Softmax

3. ConfiguraÃ§Ã£o de Treinamento

    FunÃ§Ã£o de perda: Categorical Cross-Entropy

    Otimizador: Adam (learning_rate=0.001)

    MÃ©tricas: AcurÃ¡cia, Precision, Recall, F1-Score

    Batch size: 32 ou 64

    Ã‰pocas: AtÃ© early stopping (paciÃªncia=10)

4. cGAN para Data Augmentation (Opcional)

    GeraÃ§Ã£o de imagens sintÃ©ticas condicionadas por identidade

    Balanceamento de classes minoritÃ¡rias

    Arquitetura DCGAN modificada para grayscale

ğŸ“ Estrutura do Projeto
text

projeto_facial/
â”œâ”€â”€ data/                          # Dados e datasets
â”œâ”€â”€ notebooks/                     # AnÃ¡lises exploratÃ³rias
â”œâ”€â”€ src/                           # CÃ³digo fonte
â”‚   â”œâ”€â”€ data/                      # ManipulaÃ§Ã£o de dados
â”‚   â”œâ”€â”€ models/                    # DefiniÃ§Ã£o dos modelos
â”‚   â”œâ”€â”€ training/                  # Treinamento
â”‚   â”œâ”€â”€ evaluation/                # AvaliaÃ§Ã£o
â”‚   â””â”€â”€ utils/                     # UtilitÃ¡rios
â”œâ”€â”€ configs/                       # ConfiguraÃ§Ãµes
â”œâ”€â”€ experiments/                   # Resultados experimentais
â”œâ”€â”€ reports/                       # RelatÃ³rios
â”œâ”€â”€ scripts/                       # Scripts executÃ¡veis
â””â”€â”€ outputs/                       # SaÃ­das finais

ğŸš€ Como Executar
PrÃ©-requisitos
bash

Python 3.8+
TensorFlow 2.8+
OpenCV
scikit-learn
matplotlib
numpy
pandas

InstalaÃ§Ã£o
bash

# Clonar repositÃ³rio
git clone https://github.com/seu-usuario/projeto-facial-cnn.git
cd projeto-facial-cnn

# Criar ambiente virtual
python -m venv final
source final/bin/activate  # Linux/Mac
# ou
final\Scripts\activate     # Windows

# Instalar dependÃªncias
pip install -r requirements.txt

ExecuÃ§Ã£o do Pipeline
bash

# 1. PrÃ©-processamento dos dados
python scripts/run_preprocessing.py --input_dir data/raw --output_dir data/processed

# 2. Treinamento da CNN
python scripts/train_cnn.py --config configs/cnn_config.yaml

# 3. AvaliaÃ§Ã£o do modelo
python scripts/evaluate_model.py --model_path experiments/model_final.h5 --test_dir data/processed/test

# 4. GeraÃ§Ã£o de relatÃ³rio (opcional)
python scripts/generate_report.py --output_dir reports/

ğŸ“ˆ MÃ©tricas de AvaliaÃ§Ã£o

    AcurÃ¡cia Geral: Top-1 e Top-5 accuracy

    MÃ©tricas por Classe: Precision, Recall, F1-Score

    Matriz de ConfusÃ£o: AnÃ¡lise de erros entre classes

    Curva ROC: Para avaliaÃ§Ã£o multiclasse

    Tempo de InferÃªncia: Performance em tempo real

ğŸ“Š Resultados Esperados
MÃ©trica	CNN Baseline	CNN + Augmentation	CNN + cGAN
AcurÃ¡cia (Top-1)	~85%	~88%	~90%
AcurÃ¡cia (Top-5)	~95%	~97%	~98%
F1-Score MÃ©dio	~0.84	~0.87	~0.89
Tempo InferÃªncia	<50ms	<50ms	<50ms
ğŸ§ª Experimentos Realizados

    Experimento 1: CNN baseline com prÃ©-processamento mÃ­nimo

    Experimento 2: CNN com data augmentation tradicional

    Experimento 3: CNN com aumento de dados via cGAN

    Experimento 4: Transfer learning com EfficientNet

    Experimento 5: Ensemble de modelos

ğŸ“ RelatÃ³rio TÃ©cnico

O relatÃ³rio tÃ©cnico inclui:

    RevisÃ£o bibliogrÃ¡fica sobre reconhecimento facial

    Metodologia detalhada

    AnÃ¡lise comparativa dos experimentos

    DiscussÃ£o de resultados e limitaÃ§Ãµes

    Propostas de trabalho futuro


ğŸ”§ Tecnologias Utilizadas

    Linguagem: Python 3.8+

    Deep Learning: TensorFlow 2.x / Keras

    Processamento de Imagens: OpenCV, PIL

    AnÃ¡lise de Dados: NumPy, Pandas, Matplotlib

    AvaliaÃ§Ã£o: scikit-learn

    Desenvolvimento: Jupyter Notebook, Git

âš ï¸ LimitaÃ§Ãµes e Desafios

    Variabilidade intra-classe: ExpressÃµes, iluminaÃ§Ã£o e poses diferentes

    Similaridade inter-classe: Algumas identidades sÃ£o visualmente similares

    Balanceamento de classes: DistribuiÃ§Ã£o desigual no dataset original

    Recursos computacionais: Treinamento demanda GPU com memÃ³ria suficiente

ğŸ“ˆ Trabalho Futuro

    Implementar attention mechanisms na CNN

    Explorar arquiteturas mais recentes (Vision Transformers)

    Adicionar reconhecimento de atributos (idade, gÃªnero, emoÃ§Ã£o)

    Implementar sistema em tempo real com OpenCV

    Testar com outras bases de dados (LFW, VGGFace2)

ğŸ‘¥ Autores

    Edson Vieira - Desenvolvimento e anÃ¡lise

    Prof. dr. Clodoaldo A. Lima - OrientaÃ§Ã£o

    Universidade de SÃ£o Paulo - USP - Suporte institucional

ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo LICENSE para detalhes.
ğŸ™ Agradecimentos

    Universidade de Hong Kong pelo dataset CelebA

    Comunidade TensorFlow/Keras pela documentaÃ§Ã£o

    Google Colab pelos recursos computacionais


Projeto desenvolvido para a disciplina de Aprendizado de MÃ¡quina - USP, 2025
